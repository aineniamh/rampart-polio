import yaml 

##### Configuration #####

# configfile: "pipelines/analysis_master/config.yaml"

config["output_path"] = config["output_path"].rstrip("/")
config["annotated_path"] = config["annotated_path"].rstrip("/")
config["input_path"] = config["input_path"].rstrip("/")
config_path = config["config"].rstrip("/")


barcodes = config["barcodes"].split(',')
barcode_string = ""
for i in barcodes:
    barcode_string+=" {}".format(i)

bin_string = ""
if "bin_by" in config:
    bin_string = "--bin-by " + config["bin_by"]

sample_string = ""
sample_command = ''
if config["sample"]:
    print(config["sample"])
    sample_string = config["sample"]
else:
    sample_string = "_".join(barcodes)

if sample_string=="None":
    sample_command = f' sample={sample_string}'

##### Subworkflows #####
rule all:
    input:
        config["output_path"] + f"/consensus_sequences/{sample_string}.fasta"

rule bin_to_fastq:
    input:
    params:
        barcodes = config["barcodes"],
        sample= sample_command,
        path_to_reads= config["input_path"],
        path_to_csv= config["annotated_path"],
        output_path= config["output_path"],
        min_length = config["min_length"],
        max_length = config["max_length"]
    output:
        fastq=config["output_path"] + "/binned_{sample}.fastq",
        csv=config["output_path"] + "/binned_{sample}.csv"
    shell:
        "snakemake --nolock --snakefile pipelines/bin_to_fastq/Snakefile "
        "--config "
        "input_path={params.path_to_reads} "
        "output_path={params.output_path} "
        "annotated_path={params.path_to_csv} "
        "min_length={params.min_length} "
        "max_length={params.max_length} "
        "barcodes={params.barcodes}"
        "{params.sample}"

rule assess_sample:
    input:
        fastq=config["output_path"] + "/binned_{sample}.fastq",
        csv= config["output_path"] + "/binned_{sample}.csv",
        refs = config["references_file"],
        config = config_path
    params:
        sample = "{sample}",
        output_path= config["output_path"],
        min_reads=config["min_reads"],
        min_pcent=config["min_pcent"]
    output:
        config["output_path"] + "/binned_{sample}/config.yaml"
    shell:
        "snakemake --nolock --snakefile pipelines/assess_sample/Snakefile "
        "--configfile {input.config} "
        "--config "
        "reads={input.fastq} "
        "csv={input.csv} "
        "output_path={params.output_path} "
        "references={input.refs} "
        "config={input.config} "
        "min_reads={params.min_reads} "
        "min_pcent={params.min_pcent} "
        "sample={params.sample}"

rule make_consensus:
    input:
        config=config["output_path"] + "/binned_{sample}/config.yaml"
    params:
        sample = "{sample}",
        output_path= config["output_path"]
    output:
        config["output_path"] + "/consensus_sequences/{sample}.fasta"
    run:
        with open(input.config, "r") as stream:
            new_config = yaml.safe_load(stream)
            print(new_config)
            if "analysis_stem" in new_config:
                if new_config["analysis_stem"] != None:

                    shell("snakemake --nolock --snakefile pipelines/make_consensus/Snakefile "
                        "--configfile {input.config} "
                        "--config "
                        "output_path={params.output_path} "
                        "sample={params.sample}")
                else:
                    print("No analysis stem to run polishing on.")
                    shell("touch {output}")
            else:
                print("No analysis stem to run polishing on.")
                shell("touch {output}")

